{
pub suberror LexError {
  EndOfInput
  UnexpectedEndOfFile
}

pub enum Token {
  EOF
  TAG_NAME(String)
  TEXT(String)
  ATTR_NAME(String)
  ATTR_VALUE(String)
  ATTR_VALUE_QUOTED(String)
  LANGLE
  RANGLE
  SLASH
  EQUAL
  QUOTE
  SELF_CLOSE
  CLOSE_TAG_START
} derive(Show)
}

// 主 token 函数
rule token[T : @lexbuf.IStringLexbuf](lexbuf : T) -> Token raise LexError {
  parse {
    // 结束标签开始 </（必须在 < 之前）
    "</" => { CLOSE_TAG_START }
    
    // 自闭合标签 />（必须在 / 和 > 之前）
    "/>" => { SELF_CLOSE }
    
    // 开始标签 <（必须在文本之前）
    '<' => { LANGLE }
    
    // 结束标签 >
    '>' => { RANGLE }
    
    // 等号
    '=' => { EQUAL }
    
    // 引号（单独处理，在 tokenize 中处理引号内的内容）
    ['"'] => { QUOTE }
    ['\''] => { QUOTE }
    
    // 斜杠
    '/' => { SLASH }
    
    // 标签名或属性名（字母开头，可包含字母、数字、-、_、:）
    // 注意：必须在 TEXT 规则之前，以确保优先匹配
    (['a'-'z' 'A'-'Z'] (['a'-'z' 'A'-'Z' '0'-'9' '-' '_' ':']*)) as name => {
      TAG_NAME(name)
    }
    
    // 未引号的属性值（字母、数字、-、_、:、. 等字符序列）
    (['a'-'z' 'A'-'Z' '0'-'9' '-' '_' ':' '.' '/' '\\']+) as value => {
      ATTR_VALUE(value)
    }
    
    // 文本内容（包含所有非标签字符，包括空白字符）
    // 注意：不包含 < > = " ' / 等特殊字符
    // 注意：由于 TAG_NAME 规则在前面，字母开头的序列会被优先匹配为 TAG_NAME
    (_ \ ['<' '>' '=' '"' '\'' '/'])+ as text => { 
      TEXT(text) 
    }
    
    // 单个字符作为文本（包括空白字符）
    _ as c => { 
      TEXT(String::make(1, c))
    }
    
    // EOF
    "" => { EOF }
  }
}

// 读取双引号内的属性值
rule read_quoted_value[T : @lexbuf.IStringLexbuf](buf : StringBuilder, lexbuf : T) -> Unit raise LexError {
  parse {
    '"' => { () }
    (_ \ ['"'])+ as text => {
      buf.write_string(text)
      read_quoted_value(buf, lexbuf)
    }
    _ as c => {
      buf.write_char(c)
      read_quoted_value(buf, lexbuf)
    }
    "" => { raise(UnexpectedEndOfFile) }
  }
}

// 读取单引号内的属性值
rule read_single_quoted_value[T : @lexbuf.IStringLexbuf](buf : StringBuilder, lexbuf : T) -> Unit raise LexError {
  parse {
    '\'' => { () }
    (_ \ ['\''])+ as text => {
      buf.write_string(text)
      read_single_quoted_value(buf, lexbuf)
    }
    _ as c => {
      buf.write_char(c)
      read_single_quoted_value(buf, lexbuf)
    }
    "" => { raise(UnexpectedEndOfFile) }
  }
}

{
///|
/// 将 lexer.Token 转换为 parser.Token
///|
fn convert_token(lex_token : Token) -> @parser.Token {
  match lex_token {
    EOF => @parser.EOF
    TAG_NAME(name) => @parser.TAG_NAME(name)
    TEXT(text) => @parser.TEXT(text)
    ATTR_NAME(name) => @parser.ATTR_NAME(name)
    ATTR_VALUE(value) => @parser.ATTR_VALUE(value)
    ATTR_VALUE_QUOTED(value) => @parser.ATTR_VALUE_QUOTED(value)
    LANGLE => @parser.LANGLE
    RANGLE => @parser.RANGLE
    SLASH => @parser.SLASH
    EQUAL => @parser.EQUAL
    QUOTE => @parser.QUOTE
    SELF_CLOSE => @parser.SELF_CLOSE
    CLOSE_TAG_START => @parser.CLOSE_TAG_START
  }
}

///|
/// 主 tokenize 函数，使用 moonlex 生成的 token 函数
/// 根据上下文区分标签名和属性名
///|
pub fn tokenize(
  input : String
) -> Array[(@parser.Token, Int, Int)] {
  let tokens : Array[(@parser.Token, Int, Int)] = []
  let lexbuf = @lexbuf.StringLexbuf::from_string(input)
  let mut done = false
  let mut in_tag = false  // 是否在标签内（<...>）
  let mut tag_name_seen = false  // 是否已经看到标签名
  
  while !done {
    try {
      let start_pos = lexbuf.curr_pos()
      let lex_token = token(lexbuf)
      let end_pos = lexbuf.curr_pos()
      
      // 根据上下文转换 token
      let parser_token = match lex_token {
        CLOSE_TAG_START => {
          // 结束标签开始，重置状态
          in_tag = true
          tag_name_seen = false
          convert_token(lex_token)
        }
        LANGLE => {
          in_tag = true
          tag_name_seen = false
          @parser.LANGLE
        }
        RANGLE | SELF_CLOSE => {
          in_tag = false
          tag_name_seen = false
          convert_token(lex_token)
        }
        TAG_NAME(name) => {
          if in_tag && !tag_name_seen {
            // 在标签内，且还没看到标签名，这是标签名
            tag_name_seen = true
            @parser.TAG_NAME(name)
          } else if in_tag {
            // 在标签内，且已经看到标签名，这是属性名
            @parser.ATTR_NAME(name)
          } else {
            // 不在标签内，这应该是文本内容
            @parser.TEXT(name)
          }
        }
        TEXT(text) => {
          // 在标签内，如果 TEXT 包含空白字符和字母，可能是 TAG_NAME 规则没有正确匹配
          // 尝试拆分：如果包含空白字符，尝试提取第一个单词作为 TAG_NAME 或 ATTR_NAME
          if in_tag && text.length() > 0 {
            // 检查是否包含空白字符和字母
            let mut has_whitespace = false
            let mut has_letter = false
            let mut first_letter_pos = -1
            for i = 0; i < text.length(); i = i + 1 {
              let c = text[i].unsafe_to_char()
              if c == ' ' || c == '\t' || c == '\r' || c == '\n' {
                has_whitespace = true
              } else if (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z') {
                has_letter = true
                if first_letter_pos == -1 {
                  first_letter_pos = i
                }
              }
            }
            
            if has_whitespace && has_letter && first_letter_pos >= 0 {
              // 找到第一个字母的位置，提取从第一个字母开始的单词
              let mut first_word_end = first_letter_pos
              for i = first_letter_pos + 1; i < text.length(); i = i + 1 {
                let c = text[i].unsafe_to_char()
                if c == ' ' || c == '\t' || c == '\r' || c == '\n' {
                  first_word_end = i
                  break
                }
                first_word_end = i + 1
              }
              
              if first_word_end > first_letter_pos {
                // 提取第一个单词（从第一个字母开始）
                let first_word_buf = StringBuilder::new()
                for i = first_letter_pos; i < first_word_end; i = i + 1 {
                  first_word_buf.write_char(text[i].unsafe_to_char())
                }
                let first_word = first_word_buf.to_string()
                
                // 第一个单词作为 TAG_NAME 或 ATTR_NAME
                let first_token = if !tag_name_seen {
                  tag_name_seen = true
                  @parser.TAG_NAME(first_word)
                } else {
                  @parser.ATTR_NAME(first_word)
                }
                tokens.push((first_token, start_pos + first_letter_pos, start_pos + first_word_end))
                
                // 重置 lexbuf 位置到第一个单词之后，重新处理剩余部分
                lexbuf.reset(pos=start_pos + first_word_end)
                continue
              }
            }
          }
          
          // 正常处理 TEXT
          // 检查是否是空白字符
          let is_whitespace = text.length() > 0 && {
            let mut all_whitespace = true
            for i = 0; i < text.length(); i = i + 1 {
              let c = text[i].unsafe_to_char()
              if c != ' ' && c != '\t' && c != '\r' && c != '\n' {
                all_whitespace = false
                break
              }
            }
            all_whitespace
          }
          
          if is_whitespace {
            if in_tag {
              // 在标签内的空白字符，跳过（属性之间的空白）
              // 继续读取下一个 token，不添加 token
              continue
            } else {
              // 在标签外的空白字符，保留作为文本的一部分
              @parser.TEXT(text)
            }
          } else {
            // 非空白字符，保留
            @parser.TEXT(text)
          }
        }
        QUOTE => {
          // 处理引号内的属性值
          // 先返回开始引号 token
          tokens.push((@parser.QUOTE, start_pos, end_pos))
          
          // 使用原始输入字符串读取引号内的内容
          let quote_char = input.get_char(start_pos).unwrap()
          let value_start = end_pos
          let mut value_pos = value_start
          let value_buf = StringBuilder::new()
          let mut found_end = false
          
          // 从输入字符串中读取直到找到匹配的引号
          while value_pos < input.length() && !found_end {
            match input.get_char(value_pos) {
              Some(c) => {
                if c == quote_char {
                  // 找到结束引号
                  let value = value_buf.to_string()
                  let value_end = value_pos
                  // 返回值 token
                  tokens.push((@parser.ATTR_VALUE_QUOTED(value), value_start, value_end))
                  // 返回结束引号 token
                  tokens.push((@parser.QUOTE, value_end, value_end + 1))
                  // 重置 lexbuf 位置到结束引号之后
                  lexbuf.reset(pos=value_end + 1)
                  found_end = true
                } else {
                  value_buf.write_char(c)
                  value_pos += 1
                }
              }
              None => break
            }
          }
          
          // 如果找到了结束引号，跳过当前循环
          if found_end {
            continue
          } else {
            // 如果没找到结束引号，只返回开始引号
            @parser.QUOTE
          }
        }
        SLASH => {
          // 普通的斜杠（自闭合标签 /> 已经在上面处理了）
          @parser.SLASH
        }
        _ => convert_token(lex_token)
      }
      
      match parser_token {
        @parser.EOF => {
          tokens.push((parser_token, start_pos, end_pos))
          done = true
        }
        _ => {
          tokens.push((parser_token, start_pos, end_pos))
        }
      }
    } catch {
      EndOfInput => {
        tokens.push((@parser.EOF, lexbuf.curr_pos(), lexbuf.curr_pos()))
        done = true
      }
      _ => {
        // 其他错误，添加 EOF
        tokens.push((@parser.EOF, lexbuf.curr_pos(), lexbuf.curr_pos()))
        done = true
      }
    }
  } else {
    tokens
  }
}
}
